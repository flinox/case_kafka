21/05
s0 - 1. Elabore um plano de trabalho
	- (1) Identificação das estórias
	- (2) Elaboração das tasks para as estórias	
	- (1) Planejamento das atividades e burnup das atividades
	- (2) III. Diagrama de arquitetura
	- (2) IV. Diagrama de implantação da solução

22/05
s1 - 2. Criar um ambiente em notebook próprio ou em Cloud Pública (desejável)
	- (1) Criar repositório github para armazenar o projeto

23/05
s2 - 4. Configurar um Zookeeper e subir o software via serviço contido no Systemd do Linux com um usuário de serviço “nologin” 
	- (2) Exploratório de todos os prereqs necessários para instalar o zookeeper
	- (2) Criar conta de usuario para "nologin" para instalar zookeeper
	- (2) Criar dockerfile para imagem do Zookeeper
	- (1) Gerar imagem do zookeeper e publicar
	
24/05
s3 e s4 - 3. Instalar o Apache Kafka Versão 2.2
		  5. Configurar um Broker e subir o software via serviço contido no Systemd do Linux com um usuário de serviço “nologin”  
	- (2) Exploratório de todos os prereqs necessários para instalar o kafka
	- (2) Criar conta de usuario para "nologin" para instalar kafka	
	- (2) Criar dockerfile para imagem do Kafka
	- (1) Gerar imagem do kafka e publicar

25/05
s5 - 6. Com as duas peças acima funcionando em conjunto crie um tópico de nome “test-topic”
	- (2) Exploratório de todos os prereqs necessários para instalar um "kafka client"
	- (1) Criar dockerfile para imagem do "Kafka client"
	- (2) Gerar imagem do "kafka client" e publicar no dockerhub
	- (1) Usar a imagem gerada para criar um topico chamado "test-topic" com 10 particoes e replication-set 3

26/05
s6 - 7. Crie um produtor de mensagens em java e gere uma mensagem para o Tópico “test-topic”
	- (2) Criação de um aplicativo em python/go/shell para produzir mensagem no tópico
	- (1) Produzir mensagem no tópico “test-topic”
	
26/05
s7 - 8. Crie um consumidor de mensagens em java e consuma a mensagem do Tópico “test-topic”
	- (2) Criação de um aplicativo em python/go/shell para consumir mensagem no tópico
	- (1) Consumir mensagem do tópico “test-topic”

27/05
s8 - 9. Instalar e configurar um Prometheus e um Grafana para coletar as métricas JMX do Kafka
	 10. Mostrar a métrica “Under Replicated Partitions” no Grafana
	- (2) Criar container "kafka-exporter" para coletar de metricas do kafka
	- (2) Criar container "prometheus" para pegar as metricas geradas e armazenar
	- (2) Criar container "grafana" para pegar as metricas e exibir em um dashboard
	- (3) Criar query para extrair a métrica “Under Replicated Partitions”

28/05
s9 - Preparar apresentação para system demo
	- (1) Publicacao da ultima versao no https://github.com/flinox
	- (2) Elaborar PPT para apresentacao, incluir: 
		II. Tecnologias utilizadas  Linguagens, Versões, IDE&#39;s, SO&#39;s
		III. Diagrama de arquitetura
		IV. Diagrama de implantação da solução
		I. Plano de Trabalho (previsto e realizado)
		 Caso haja algum desvio entre o planejamento original e a execução, explique o que houve.
		 Caso o plano de trabalho foi seguido sem desvio, comente os motivos para esse resultado.



29/05
s10 - Itens Desejáveis (Diferencial)
	- (1) Criar cópia de tudo que foi feito e tentar:
	- (5) Colocar o ambiente na AWS
		- Criar conta gratuita na AWS
		- Criar EC2
		- Criar Repositorio ECR para armazenar os containers
	- (8) Segurança
		(?)  Configurar o Zookeeper e o Broker para se comunicarem de forma segura usando Kerberos.
		(?)  Configurar o segurança com TLS no Broker 
		(?)  Com as duas peças acima funcionando em conjunto crie um tópico de nome “secure-topic”
		(?)  Configure o produtor e o consumidor para comunicar com o broker com TLS
		(?)  Crie um produtor de mensagens em java e gere uma mensagem para o Tópico “secure-topic” de forma segura (usando TLS)
		(?)  Crie um consumidor de mensagens em java e consuma a mensagem do Tópico “secure-topic” de forma segura (usando TLS)
